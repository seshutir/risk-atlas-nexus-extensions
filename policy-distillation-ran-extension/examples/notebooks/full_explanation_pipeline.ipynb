{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a92b30a6-4a3c-4215-a0b8-3f61480ccba3",
   "metadata": {},
   "source": [
    "# Generating global explanations of LLM-as-a-Judge using GloVE algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3432262-2b4f-4de2-a5d6-43a835b1db78",
   "metadata": {},
   "source": [
    "### Installation instructions \n",
    "\n",
    "1. All necessary packages are listed in the requirements.txt file. To install them:\n",
    "\n",
    "```{bash}\n",
    "conda create -n glove python=3.9\n",
    "conda activate glove\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "2. Follow the instructions to install FactReasoner [here](../fm_factual/README.md)\n",
    "\n",
    "3. Make sure to create a .env file at root level with the following contents:\n",
    "```{bash}\n",
    "RITS_API_KEY= ...\n",
    "LOCAL_ROOT= {This is absolute path to this repository}\n",
    "CACHE_DIR = {Anywhere you want cache files for Merlin}\n",
    "MERLIN_PATH = {Anywhere you installed merlin earlier}\n",
    "```\n",
    "\n",
    "4. Merlin requires sudo privileges to run. If using jupyter lab make sure to start it in sudo mode:\n",
    "\n",
    "```{bash}\n",
    "sudo jupyter lab\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a916d009-0e56-412a-8c18-8e9843c3bbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a908c357-c7e2-4a50-a7f9-a609aed02ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setup logging\n",
    "# logger = logging.getLogger('logger')\n",
    "# logger.setLevel(logging.INFO)\n",
    "# fh = logging.FileHandler(f'../logs/{datetime.datetime.now().strftime(\"%m_%d__%H_%M\")}.log')\n",
    "# fh.setLevel(logging.INFO)\n",
    "# logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6e5f863-b414-45e9-8d3a-ed1d76040134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is for my jupyter to be able to see this repository, might not be needed for everyone\n",
    "# load_dotenv()\n",
    "# local_root = os.getenv('LOCAL_ROOT')\n",
    "# sys.path.append(local_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85ad44e9-b889-465b-b228-37c87577ae16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seshu/Documents/2025/policy-distillation-ran-extension/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-26 12:22:30 [__init__.py:216] Automatically detected platform cpu.\n"
     ]
    }
   ],
   "source": [
    "from risk_policy_distillation.pipeline.clusterer import Clusterer\n",
    "from risk_policy_distillation.pipeline.concept_extractor import Extractor\n",
    "from risk_policy_distillation.evaluation.evaluate import Evaluator\n",
    "from risk_policy_distillation.pipeline.pipeline import Pipeline\n",
    "from risk_policy_distillation.models.explainers.local_explainers.lime import LIME\n",
    "from risk_policy_distillation.utils.data_util import load_ds\n",
    "from risk_policy_distillation.models.guardians.granite_guardian import GraniteGuardian\n",
    "from risk_policy_distillation.models.guardians.granite_guardian_batch import GGRits\n",
    "from risk_policy_distillation.llms.rits_component import RITSComponent\n",
    "from risk_policy_distillation.datasets.prompt_dataset import PromptDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af275e10-5696-438d-a1d8-aace70c778ca",
   "metadata": {},
   "source": [
    "### Create an LLM-as-a-Judge\n",
    "\n",
    "To create a wrapper for your LLM-as-a-Judge create either a GraniteGuardian object or inherit the [Judge](../src/models/guardians/judge.py) class to create.\n",
    "You also need to define the specific of the task, such as the criterion the LLM-as-a-Judge is using and label names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4397879d-9345-415a-a811-847dbccc5304",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RITSBatchModel.__init__() missing 1 required positional argument: 'output_labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      2\u001b[39m guardian_config = {\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtask\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mharm detection\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcriterion\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mharm\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m     \u001b[33m'\u001b[39m\u001b[33moutput_labels\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m]\n\u001b[32m      9\u001b[39m }\n\u001b[32m     11\u001b[39m guardian_model = \u001b[33m'\u001b[39m\u001b[33mibm-granite/granite-guardian-3.2-5b\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m guardian = \u001b[43mGGRits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mguardian_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguardian_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/2025/policy-distillation-ran-extension/src/risk_policy_distillation/models/guardians/granite_guardian_batch.py:35\u001b[39m, in \u001b[36mGGRits.__init__\u001b[39m\u001b[34m(self, model_path, config)\u001b[39m\n\u001b[32m     18\u001b[39m i = rits_models.index(model_path)\n\u001b[32m     19\u001b[39m rits_config = {\n\u001b[32m     20\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbase-url\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mhttps://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     21\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mnum-parallel-requests\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m10\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m         ]\n\u001b[32m     34\u001b[39m     }\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[38;5;28mself\u001b[39m.guardian_model = \u001b[43mRITSBatchModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m                                     \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrits_model_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m                                     \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrits_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;28mself\u001b[39m.guardian_tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
      "\u001b[31mTypeError\u001b[39m: RITSBatchModel.__init__() missing 1 required positional argument: 'output_labels'"
     ]
    }
   ],
   "source": [
    "# Define a guardian model and the task\n",
    "guardian_config = {\n",
    "    'task': 'harm detection',\n",
    "    'criterion': 'harm', \n",
    "    'criterion_definition': 'Content is harmful by common-sense understanding',\n",
    "    'labels': [0, 1],\n",
    "    'label_names': ['harmless', 'harmful'],\n",
    "    'output_labels': [0, 1]\n",
    "}\n",
    "\n",
    "guardian_model = 'ibm-granite/granite-guardian-3.2-5b'\n",
    "guardian = GGRits(guardian_model, guardian_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f2b11f-d205-4f81-93bb-9ab3dd785db8",
   "metadata": {},
   "source": [
    "###Â Create a dataset\n",
    "\n",
    "To explain the LLM-as-a-Judge you need to provide a dataset. [AbstractDataset](../src/models/datasets/abs_dataset.py) class provides a wrapper for a dataframe you want to explain. You can use [PromptDataset](../src/models/datasets/prompt_dataset.py) or [PromptResponseDataset](../src/models/datasets/prompt_response_dataset.py) depending on whether your dataframe consists of only prompts or prompt-response pairs. You can also create a custom dataset by inheriting the Dataset class. \n",
    "\n",
    "You have to provide a config with information on column name mapping. Additional parameters: *flip_labels* indicates whether labels of the dataframe should be flipped in preprocessing step (e.g. for BeaverTails where labels indicate that the content is safe rather than harmful); *split* indicates whether a train-val-test split needs to be performed during preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc4d137-23e8-47da-afbd-88947bc07643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a test dataset\n",
    "dataframe = pd.DataFrame([[0, 'How can I kill some time?', 0], \n",
    "                          [1, 'How can I shoot my shot?', 0], \n",
    "                          [2, 'Can can I bang my head to a song?', 1]], \n",
    "                        columns = ['Index', 'prompt', 'label'])\n",
    "\n",
    "data_config = {'general':{\n",
    "                   'dataset_name': 'test'\n",
    "                },\n",
    "               'data': {\n",
    "                   'index_col': 'Index', # index column name\n",
    "                   'prompt_col': 'prompt', # prompt column name\n",
    "                   'label_col': 'label', # true label name\n",
    "                   'flip_labels': False, # whether to flip labels (e.g. BeaverTails has is_safe instead of is_harmful)\n",
    "               }, \n",
    "               'split': {\n",
    "                   'split': False # whether to split dataset into train, val, test\n",
    "               }}\n",
    "\n",
    "# Wrap the dataframe \n",
    "dataset = PromptDataset(data_config, dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fddf0ab-bec7-4d85-9cef-19ce8e067f6e",
   "metadata": {},
   "source": [
    "### Define components\n",
    "\n",
    "Next we need to define how to access the LLM-based components. You can use a [RITSComponent](../src/models/components/llms/rits_component.py) or [OllamaComponent](../src/models/components/llms/ollama_component.py) wrappers for querying an LLM. You just need to pass the name of the LLM. Otherwise, you can create a custom LLM wrapper by inheriting [LLMComponent](../src/models/components/llms/llm_component.py) class. \n",
    "\n",
    "You can also define a local word-based explainer component which is used by the CloVE algorithm. At the moment, you can use LIME or create custom word-based explainer by inheriting [LocalExplainer](../src/models/local_explainers/local_explainer.py) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40fdd5a-ed67-4e90-85c5-7a95b62faeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an LLM that is used for generating concepts and labels \n",
    "llm_component = RITSComponent('llama-3-3-70b-instruct', 'meta-llama/llama-3-3-70b-instruct')\n",
    "local_explainer = LIME(data_config['general']['dataset_name'], guardian_config['label_names'], n_samples=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d419d3d-922e-4e10-aefe-3e8617e65e01",
   "metadata": {},
   "source": [
    "### Create and run the explanation generation pipeline\n",
    "\n",
    "Pipeline streamlines local and global explanation generation process. Extractor executes the CLoVE algorithm and generates a set of local explanations, and Clusterer executes GloVE algorithm and merges the local explanations into a global one. \n",
    "\n",
    "Pass ```lime=False``` to pipeline creation step if no local word-based verification is done. SImilarly, use ```fr=False``` if FactReasoner is not used to verify global explanations.\n",
    "\n",
    "The resulting local and global explanations are saved in the path folder passed to the pipeline.run() call. \n",
    "The execution logs can be found in the logs folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14061008-7065-4a69-857d-ca6e89b9b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(extractor = Extractor(guardian, llm_component, guardian_config['criterion'], guardian_config['criterion_definition'], local_explainer),\n",
    "                    clusterer = Clusterer(llm_component, guardian_config['criterion_definition'], guardian_config['label_names'], n_iter=10),\n",
    "                    lime=True, \n",
    "                    fr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9045eb24-1f1d-4398-8b37-1c19fad6f10d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expl = pipeline.run(dataset, \n",
    "                    path='../results/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c809935b-a905-471c-8157-66fd59b72ac5",
   "metadata": {},
   "source": [
    "### Printing the global explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dead377-e530-46ab-a647-f02b87e5808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the rules\n",
    "for i, argument in enumerate(expl.rules):\n",
    "    decision = guardian.label_names[expl.predictions[i]]\n",
    "    rule = '{} IF {}'.format(decision, argument)\n",
    "\n",
    "    if expl.despites[i] != 'none':\n",
    "        rule += ' DESPITE '\n",
    "\n",
    "        indent = ' ' * (len(rule))\n",
    "        for d in expl.despites[i]:\n",
    "            rule += '{}\\n'.format(d) + indent\n",
    "    else:\n",
    "        rule += '\\n'\n",
    "\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0074e8b7-e61a-4a9c-8a2f-36e2bbeb4811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
