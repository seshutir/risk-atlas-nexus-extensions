from lime.lime_text import LimeTextExplainer

from risk_policy_distillation.models.explainers.local_explainers.local_explainer import (
    LocalExplainer,
)


class LIME(LocalExplainer):

    def __init__(self, dataset_name, label_names, n_words=6, n_samples=1000):
        """
        Lime explainer for word-based explanations.
        :param dataset_name: name of the datasets
        :param label_names: list of label names
        :param n_words: number of the most important words to be extracted
        :param n_samples: neighbourhood size to be generated by LIME
        """
        super().__init__()
        self.dataset_name = dataset_name
        self.n_words = n_words
        self.n_samples = n_samples

        self.explainer = LimeTextExplainer(class_names=label_names)

    def explain(self, text, decisions, prediction_func):
        """
        Explain a single text input for each decision using LIME
        :param text: textual input
        :param decisions: a list of all possible decisions in the task
        :param prediction_func: a function predicting probabilities of outcome to be explained
        :return: a Dict object where keys are possible decisions and values are lists of important words
                 extracted by LIME supporting that decision
        """

        if not len(text.strip(' ')):
            return {d: [] for d in decisions}

        exp = self.explainer.explain_instance(text,
                                              prediction_func,
                                              num_features=self.n_words,
                                              labels=decisions,
                                              num_samples=self.n_samples)
        res = {}
        for d in decisions:
            scores = exp.as_list(d)
            supporting = [w for w, s in scores if s > 0]

            res[d] = supporting

        return res
